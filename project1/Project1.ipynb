{"cells":[{"cell_type":"code","execution_count":1,"id":"052b75c3","metadata":{"id":"052b75c3"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import ortho_group\n","from numpy.linalg import qr\n","from numpy.random import default_rng\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import Ridge\n","from sklearn.metrics import classification_report\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.feature_selection import SelectPercentile\n","from sklearn.feature_selection import f_classif\n","from sklearn.metrics import f1_score\n","import random"]},{"cell_type":"markdown","id":"eebb30ed","metadata":{"id":"eebb30ed"},"source":["## Mandatory Part"]},{"cell_type":"markdown","id":"e69d14f2","metadata":{"id":"e69d14f2"},"source":["Note: every run you may get different results, so the exact numbers and parameters may differ. However we run everything several times before drawing conclusions so you shouldn't see too much difference when you rerun it."]},{"cell_type":"markdown","id":"bfe46f10","metadata":{"id":"bfe46f10"},"source":["### 1. Read Data"]},{"cell_type":"code","execution_count":2,"id":"ed354329","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":262,"status":"error","timestamp":1712862902268,"user":{"displayName":"Francisco Boudagh","userId":"17739828160985964623"},"user_tz":-120},"id":"ed354329","outputId":"ddf0b77c-dd80-4aca-ebdb-deffead4789c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of nulls in features: 0\n","Number of nulls in labels: 0\n"]}],"source":["x = pd.read_csv('TCGAdata.txt', sep=\" \", header= 0) #files separated by \"\" and first column=header\n","\n","y = pd.read_csv('TCGAlabels.txt',header=0, sep=\" \",index_col=0)\n","y=y[\"x\"]\n","\n","print(\"Number of nulls in features:\", sum(x.isnull().sum())) # No nulls\n","print(\"Number of nulls in labels:\", y.isnull().sum())"]},{"cell_type":"markdown","id":"c62d4e23","metadata":{"id":"c62d4e23"},"source":["### 2. Scale data and Explore PCA"]},{"cell_type":"markdown","id":"dfbe3118","metadata":{"id":"dfbe3118"},"source":["I am going to explore the PCs of the training data in ordet to come up with a potential number of principal components to be chosen. How to select PCs?\n","\n","- Ratio of explained variance: Each PC indicates the variance along the direction of its principal component. Select the amount of vaiance as a % of varaince to be explained i.e. 90% of explained variance\n","\n","- Elbow method: make a scree plot to see the significance of each component\n","\n","- Cross validation: when PCA is followed by regression/classification, we can make the number of principal components k as a varaible to chose in the pipeline, therefore it can be trained\n","\n","\n","PCA is fitted better after standarizing the data, as some features can be more widespread than others. For example, height of a person could go from 160cm to 190cm, but the net worth of a person could go from 0€ to Millions of €. We also apply the technique only to the train data, as the test data is the one we want to use to simulate our predictions."]},{"cell_type":"code","execution_count":null,"id":"a7ac45b4","metadata":{"id":"a7ac45b4"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)#Split the data into training and test sets\n","X_pp = StandardScaler().fit_transform(X_train) #center data\n","pca=PCA()\n","pca_data = pca.fit_transform(X_pp) #compute PCA"]},{"cell_type":"markdown","id":"8b6ed18a","metadata":{"id":"8b6ed18a"},"source":["#### 2.1 Ratio of explained variance"]},{"cell_type":"code","execution_count":null,"id":"160693e3","metadata":{"id":"160693e3","outputId":"a6e0045f-ff40-4230-94c2-6ec07181c7d5"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdY0lEQVR4nO3df7wcdX3v8debc0QKqKik3iSAQY0iWn4kB65SK1DaChqgKFxAWhU1P5rUSr1W4XrvI0Fq23utFeWHJCBiey1UKV4DouJDEGgpknP4FX4YiEElhEqoClQRSPzcP2YO2Sy7Z/fMntn57pn38/GYx9mZnZ1572j2w3e+M99RRGBmZjaRHaoOYGZm6XOxMDOzjlwszMysIxcLMzPryMXCzMw6Gq46wGTtvvvuMWfOnKpjwKZNMGuWM5jZQBgbG3s0ImYU/fzAFYs5c+YwOjpadQwYG4P5853BzAaCpB/18nmfhjIzs45cLIoaGak6QRoZzKwWXCzMzKwjFwszM+vIxaKo5curTpBGBjOrhdKKhaSLJT0i6a4270vSZyWtl3SnpHllZSnFihVVJ0gjg5nVQpkti0uAIyd4/yhgbj4tAj5XYpapl8L9DSlkMLNaKK1YRMQNwE8nWOVY4O8jczOwm6SZZeWZcg8/XHWCNDKYWS1U2WcxG3iwYX5jvuw5JC2SNCppdPPmzX0JZ2Zm21RZLNRiWcsnMUXEqogYiYiRGTMK360+teYl0MWSQgYzq4Uqi8VGYM+G+T2ATRVlmbyxsaoTpJHBzGqhymKxGnhXflXUG4DHImJwTsIvWlR1gjQymFktqKxncEu6FDgM2B34CbAceB5ARFwgScC5ZFdM/RI4NSI6jhA4MjISSQwkKEHVzy9PIYOZDQRJYxFReIyg0kadjYiTO7wfwLKy9m9mZlPHd3CbmVlHLhZFPfRQ1QnSyGBmteBiUVQKVyKlkMHMasHFoqhjjqk6QRoZzKwWXCzMzKwjFwszM+vIxaKolSurTpBGBjOrBReLolK4ezqFDGZWCy4WRanVOIg1zGBmteBiYWZmHblYmJlZRy4WRS1YUHWCNDKYWS24WBR15ZVVJ0gjg5nVgotFUUcfXXWCNDKYWS24WBR11VVVJ0gjg5nVgouFmZl15GJhZmYduVgUlcLjTFPIYGa14GJR1KpVVSdII4OZ1YKLRVGLF1edII0MZlYLLhZmZtaRi4WZmXXkYlHU6tVVJ0gjg5nVgotFUfPnV50gjQxmVgsuFkXNnl11gjQymFktuFiYmVlHLhZmZtaRi0VRCxdWnSCNDGZWCy4WRaVw93QKGcysFlwsikrhSqQUMphZLbhYFHXrrVUnSCODmdWCi4WZmXXkYlHUzJlVJ0gjg5nVgotFUZs2VZ0gjQxmVgsuFkWtWFF1gjQymFktlFosJB0paZ2k9ZJOb/H+iyRdKekOSXdLOrXMPFPqzDOrTpBGBjOrhdKKhaQh4DzgKGBf4GRJ+zattgy4JyL2Bw4DPiVpx7IymZlZMWW2LA4G1kfEhoh4GrgMOLZpnQBeIEnArsBPgS0lZjIzswLKLBazgQcb5jfmyxqdC7wW2ASsBT4YEb9u3pCkRZJGJY1u3ry5rLyTMzpadYI0MphZLZRZLNRiWTTNvwW4HZgFHACcK+mFz/lQxKqIGImIkRkzZkx1TjMz66DMYrER2LNhfg+yFkSjU4ErIrMeeADYp8RMU2dkpOoEaWQws1oos1isAeZK2jvvtD4JaH4O6I+BIwAkvQx4DbChxExmZlbAcFkbjogtkv4U+BYwBFwcEXdLWpK/fwFwFnCJpLVkp60+GhGPlpXJzMyKKa1YAETE1cDVTcsuaHi9CfiDMjOUZvnyqhOkkcHMakERzX3OaRsZGYlRXwVkZjYpksYionBHp4f7KGrWrKoTpJHBzGrBxaKohx+uOkEaGcysFrouFpJ2KTOImZmlq2OxkHSIpHuAe/P5/SWdX3qy1M2bV3WCNDKYWS1007L4NNmd1v8BEBF3AG8uM9RAGBurOkEaGcysFro6DRURDzYt2lpClsGyaFHVCdLIYGa10E2xeFDSIUBI2lHSh8lPSdXahRdWnSCNDGZWC90UiyVkz52YTTbe0wH5vJmZ1UTHO7jz4TdO6UMWMzNLVDdXQ31R0m4N8y+WdHGpqQbBQw9VnSCNDGZWC92chtovIn4+PhMRPwMOLC3RoEjhSqQUMphZLXRTLHaQ9OLxGUkvoeQBCAfCMcdUnSCNDGZWC9386H8KuEnS5fn8CcAnyotkZmap6diyiIi/B44HfgI8Arw9Iv6h7GBmZjaxZcuWMTw8zLJly7Z73eo9YH5PO4uIjhPZw4tmAXuNT918roxp/vz5kYSVK6tOkEYGM5sSS5cujaGhoVi6dGnb183rDQ0NBRBDQ0PbvY6Ilu9FD7+93RSKDwCPAncDdwJrgTt72WkvUzLFwsysC90WgXY//BMVgW6LytKlS/tSLNYDL+1lJ1M5JVMssgPvDGY1MZkf5iJFoEjLYjKA0Si5WFwHDPeyk6mcXCwSy2A24Mo65TPZIlC2fhSLzwP/ApwBfGh86mWnvUwuFollMEtImef9i7YsUtGPYrG81dTLTnuZkikWCxZUnSCNDGZ9kMJ5/0FXerFIbUqmWJhZz6a6CJR93n+Q9aNlMQP4JHA1cO341MtOe5mSKRYp/Fd9ChnMWqiqCFh7/SgW1wDvI3uGxaHAxcD/7mWnvUzJFIsU+gtSyGC15SIwWPpRLMbyv3c2LLu+l532MrlYJJbBpp2p6Bh2EUhPP4rFzfnfbwFvIxtx9ge97LSXycUisQw2kIq0CprfcxEYLP0oFguAFwGvz++5GAOO6WWnvUzJFAuzBJXZKmh+zwaLr4aqSgrjMqWQwfqu7HsGbHoqrVgAH8n/ngN8tnnqZae9TMkUixROAaWQwUrT7gfd9wxYEWUWi6Pzv+9uNfWy014mF4vEMtik9XpZqYuAFVHqaSiyock/2csOpnpysUgsg7VU5mWlZkX0o4O7shvwWk3JFIvVq6tOkEaGGvNlpTZIei0WyrbRnqRPAXOBrwC/GF8eEVdM+MGSjIyMxOjoaBW73t6mTTBrljPUwLJly1i5ciWLFy8GePb1ypUr2bp1K0NDQ2zZsoXh4eFn58ffb/7MeeedV+VXsRqTNBYRI4U30KmaAF9oMV3cS4XqZUqmZZHCKaAUMkwT7juw6Y6yWxapSaZlIUHVxy6FDAOsscXQ2EoAtmsxtGtZuJVgg6TXlkU3p6F2Ihsb6nXATuPLI+K9XYQ7EvgMWUf5RRHxNy3WOQw4G3ge8GhEHDrRNl0sEsuQuIl+6H3ayOqkH6ehvgKcBfyA7LLZa4DPdPG5ofwzrwB2BO4A9m1aZzfgHmCvfP43O203mdNQCxdWnSCNDAkoOnSFTxtZndCHq6Fuy//emf99Hl1cIQW8EfhWw/wZwBlN6ywF/nIygZMpFtZXZQxdYVYn/SgWt+R/byAbH2p3YEMXnzue7NTT+PwfA+c2rXM2cB7wXbIxp97VabvJFIt586pOkEaGEk3FXctmlulHsXg/8GKyZ1lsAB4BFnfxuRNaFItzmtY5F7gZ2CUvQvcDr26xrUXAKDC61157lXc0JyOFK5FSyNCjblsMvvLIrDelFYu8L+FjwCsLbbi701CnAysa5j8PnDDRdpNpWaTwQ51ChgKKtBjMrDe9Fosdntvl/ayTgV2BayR9T9JpkmZOsH6zNcBcSXtL2hE4CVjdtM7XgN+RNCxpZ+C/kj2RL30zJ3MopnGGLi1btozh4eFnr07aunXrs1ccjV+NBGw3f95557FlyxZfkWSWgm4qCvAG4NPAj8mewb2wy8+9FbiP7Kqoj+XLlgBLGtb5C7JWzF3AaZ22mUzLwp6j26uS3GIw6z/6+TwL4DDgNuCpXnbay5RMsVi+vOoESWQoclWSmfVf6cUCOAj4O+BHwPXAnwC797LTXqZkikUK/QUVZOi2xeDiYJaW0ooF8Ff56aNR4MPAHr3saKomF4v+ZOj2wTsuCmaDocxisZwWl7FWPblYlJOh6OB5ZjYYei0Wba+GiogzI+K+oh3n014K41P1mKHdFUqw/VVJvkLJzCpvKUx2SqZlMTpadYJCGbq96c3MphdKvM/CJjJSfPDGfmZobD0Abe9xcIvBzCbStlhImjfR1M+QNjndnl5ygTCzbrV9noWk6/KXOwEjZEOMC9gP+F5EvKkvCZv4eRatM7R7kE/jcxpcFMzqq9fnWUzUwX14RBxOdn/FvIgYiYj5wIHA+qI7nDaWL69098uWLePjkk8vmVlfdPOkvNsj4oBOy/olmZZFxRqf8tb86E8XBjNrVlrLosG9ki6SdJikQyVdyKAM9lemWbP6vsvGvojFixfzEDw7AJ9bEGZWpm6fwf0nwJvzRTcAn4uIX5WcraVkWhZ96LNobi00tyaS6Dcxs4FQessiLwoXAKdHxHER8emqCkUddHslk5lZP3UsFpKOAW4HvpnPHyCp+bkU9TOvnKuHJ3rWw3NONZWUwcysWTd9FsuBg4GfA0TE7cCc0hINirGxKdtUc19E11cyTWEGM7OJdFMstkTEY6UnGTSLFhX+6ER3VU+qo7qHDGZmk9FNsbhL0juBIUlzJZ0D3FRyrvRdeGHhj05ZX0QPGczMJqObYvEB4HXAU8ClwOPAaSVmmpbanWoCX/ZqZunreOlsagb10tnnXPZaQQYzq6/SL52V9GpJqyRdI+na8anoDqeNhx7quMpErYl+ZTAzmwrd3JR3B9l9FmPA1vHlEVHJpTjJtCyuvBKOPnrCVUppTUwyg5kZ9Ge4jy0R8bmIuCUixsanojucNo455jmLmq9yKv0muhYZzMzK0E3LYgXwCPBVsk5uACLip6UmayOZlkWL/oLSWxJdZDAza6UfLYt3A39BdrnsWD4l8GudhtL7JczMEuCroYpatQoWLep/a6JFBjOzTnptWQxPsOHfjYhrJb291fsRcUXRnQ66Z0eDveOO7Z5E13cuFGbWJxM9VvXMiFgu6Qst3o6IeG+50VpLoWUxPDzMlq1bGa6iNdHIfRZm1qXSWhYRsTz/e2rRjU9XixcvhvPPd9+EmdVGV30Wkt5GNuTHTuPLIuLjJeZqK4WWBZDGf9WnkMHMBkI/7uC+ADiRbIwoAScALy+6w2ljwYKqE6SRwcxqoZtLZw+JiHcBP4uIM4E3AnuWGystzTfbAdnd01VLIYOZ1UI3xeLJ/O8vJc0CngH2Li9SepqHFAfSGGYjhQxmVgvdFIurJO0GfBK4FfghcFmJmZLT8ma7q66qLlBKGcysFiZ1U56k5wM7VfnkPHdwJ5bBzAZCaR3ckt7ePAFvA45od6PedNKyn8LMrKYmuimv1c1446b9TXmVDuNhZjbFSmtZRMSpE0xdFQpJR0paJ2m9pNMnWO8gSVslHV/kS5Sh46CAq1b1N1CqGcysFroZovylwHLgTUAA/wJ8PCL+o8PnhoD7gN8HNgJrgJMj4p4W630b+BVwcURcPtF23WeRWAYzGwj9GKL8MmAz8A7g+Pz1P3XxuYOB9RGxISKezrdzbIv1PgD8M9kzM8zMLEHdFIuXRMRZEfFAPv0lsFsXn5sNPNgwvzFf9ixJs4HjyB7b2pakRZJGJY1u3ry5i10X405tM7PWuikW10k6SdIO+fTfgK938Tm1WNZ8zuRs4KMRsbXFuts+FLEqIkYiYmTGjBld7LqYljfftbN6dWk5upZCBjOrhW6KxWLgH8keqfoU2emkD0l6QtLjE3xuI9sPC7IHsKlpnRHgMkk/JDvFdb6kP+wu+tSb1JPu5s8vP9AgZDCzWijtSXmShsk6uI8AHiLr4H5nRNzdZv1LgKvcwT1gGcxsIPRj1Nn3Nc0PSVre6XMRsQX4U+BbwL3AlyPibklLJC0pGtjMzPqv7cOPGhwh6R3A+4DdgYuB67vZeERcDVzdtKxlZ3ZEvKebbZqZWf91bFlExDuBLwJryTq2T4uID5cdrB96uvpp4cKpDzSIGcysFrq5KW8u24rFa4F7gA9FxC/Lj/dcU9ln4SE9zKwu+nFT3pXA/4qIxcChwP1kndUDb1JXPzVL4UqkFDKYWS1007J4YUQ83rRsbkTcX2qyNnw1VGIZzGwglDlE+UcAIuJxSSc0vX1q0R2amdngmeg01EkNr89oeu/IErIMlpkzq06QRgYzq4WJioXavG41Xz+bmm9Gr2kGM6uFiYpFtHndar5+VqyoOkEaGcysFiYqFvtLelzSE8B++evx+d/qU74pN2Ujy5555tQEGvQMZlYLpY0NVZZer4aasnsrUrgSKYUMZjYQ+nGfxbTS070VZmY1VbuWxZQZG6v+prgUMpjZQHDLwszMSudiUdRI4QI9vTKYWS24WJiZWUcuFmZm1pGLRVHLOz4ssB4ZzKwWalEspuxGvEYp3D2dQgYzq4VaXDpbykOOZs2qfmymFDKY2UDwpbNdKOVGvIcfnrptDXIGM6uFWrQsSpHCUBspZDCzgeCWRVXmzas6QRoZzKwWXCyKGhurOkEaGcysFlwsilq0qOoEaWQws1pwsSjqwgurTpBGBjOrBRcLMzPraFoWi1JuwjMzq7FpeelsKTfhNdu0KbsprkopZDCzgeBLZ1voy9PwUrgSKYUMZlYL07Jl0Rcp3BCXQgYzGwhuWZiZWelcLMzMrCMXi6JWrqw6QRoZzKwWXCyKSuHu6RQymFktuFgUJVWdII0MZlYLpRYLSUdKWidpvaTTW7x/iqQ78+kmSfuXmcfMzIoprVhIGgLOA44C9gVOlrRv02oPAIdGxH7AWcCqsvKYmVlxZbYsDgbWR8SGiHgauAw4tnGFiLgpIn6Wz94M7FFinqm1YEHVCdLIYGa1UGaxmA082DC/MV/WzvuAb7R6Q9IiSaOSRjdv3jyFEXtw5ZVVJ0gjg5nVQpnFolXva8vbjSUdTlYsPtrq/YhYFREjETEyY8aMljvr++CBRx/dn/2knsHMaqG04T4kvRFYERFvyefPAIiIv25abz/gq8BREXFfp+22G+6jL4MHNkphqI0UMpjZQEh5uI81wFxJe0vaETgJWN24gqS9gCuAP+6mUEykL4MHmpnVVKkDCUp6K3A2MARcHBGfkLQEICIukHQR8A7gR/lHtnSqfB5IMLEMZjYQem1ZeNRZM7MaSPk01PS2KoFbQlLIYGa14GJRVAp9IylkMLNacLEwM7OOXCzMzKwjF4uiVq/uvE4dMphZLbhYFDV/ftUJ0shgZrXgYlHU7ImGuapRBjOrBRcLMzPryMXCzMw6crEoauHCqhOkkcHMasHFoqgU7p5OIYOZ1YKLRVEpXImUQgYzqwUXi6JuvbXqBGlkMLNacLEwM7OOBrpY9P1Rqo1mzuz/PlPMYGa1MNDPs+j7o1TNzAZUrZ9nUemjVFes6P8+m6WQwcxqYaBbFpVK4ZGmKWQws4FQ65aFmZn1h4uFmZl15GJRVAqnwlLIYGa14GJhZmYduVgUNVK4n2h6ZTCzWnCxMDOzjlwszMyso4G7z0LSE8C6qnMkYnfg0apDJMLHYhsfi218LLZ5TUS8oOiHh6cySZ+s6+XGkulE0qiPRcbHYhsfi218LLaR1NPlkz4NZWZmHblYmJlZR4NYLPws0W18LLbxsdjGx2IbH4ttejoWA9fBbWZm/TeILQszM+szFwszM+tooIqFpCMlrZO0XtLpVefpJ0l7SrpO0r2S7pb0wXz5SyR9W9L9+d8XV521HyQNSbpN0lX5fF2Pw26SLpf0/fz/G2+s8bH48/zfxl2SLpW0U52OhaSLJT0i6a6GZW2/v6Qz8t/SdZLe0mn7A1MsJA0B5wFHAfsCJ0vat9pUfbUF+O8R8VrgDcCy/PufDnwnIuYC38nn6+CDwL0N83U9Dp8BvhkR+wD7kx2T2h0LSbOBPwNGIuL1wBBwEvU6FpcARzYta/n989+Ok4DX5Z85P/+NbWtgigVwMLA+IjZExNPAZcCxFWfqm4h4OCJuzV8/QfajMJvsGHwxX+2LwB9WErCPJO0BvA24qGFxHY/DC4E3A58HiIinI+Ln1PBY5IaB35A0DOwMbKJGxyIibgB+2rS43fc/FrgsIp6KiAeA9WS/sW0NUrGYDTzYML8xX1Y7kuYABwLfA14WEQ9DVlCA36wwWr+cDXwE+HXDsjoeh1cAm4Ev5KfkLpK0CzU8FhHxEPC3wI+Bh4HHIuIaangsmrT7/pP+PR2kYqEWy2p33a+kXYF/Bk6LiMerztNvkhYAj0TEWNVZEjAMzAM+FxEHAr9gep9maSs/F38ssDcwC9hF0h9Vmyppk/49HaRisRHYs2F+D7JmZm1Ieh5ZofhSRFyRL/6JpJn5+zOBR6rK1ye/DRwj6YdkpyJ/V9L/pX7HAbJ/Exsj4nv5/OVkxaOOx+L3gAciYnNEPANcARxCPY9Fo3bff9K/p4NULNYAcyXtLWlHss6Z1RVn6htJIjs3fW9E/F3DW6uBd+ev3w18rd/Z+ikizoiIPSJiDtn/B66NiD+iZscBICL+HXhQ0mvyRUcA91DDY0F2+ukNknbO/60cQdavV8dj0ajd918NnCTp+ZL2BuYCt0y0oYG6g1vSW8nOVw8BF0fEJ6pN1D+S3gTcCKxl27n6/0HWb/FlYC+yfzAnRERzJ9e0JOkw4MMRsUDSS6nhcZB0AFlH/47ABuBUsv8IrOOxOBM4kezKwduA9wO7UpNjIelS4DCyYdl/AiwH/h9tvr+kjwHvJTtep0XENybc/iAVCzMzq8YgnYYyM7OKuFiYmVlHLhZmZtaRi4WZmXXkYmFmZh25WFjlJG2VdHs+WuhXJO3cZr2bCm5/RNJne8j3n22W/xdJl0n6gaR7JF0t6dVF95MCSYdJOqTqHJYeFwtLwZMRcUA+WujTwJLGN8dHw4yIQj9iETEaEX/We8ztMgn4KvDdiHhlROxLdt/Ly6ZyPxU4jOzOZ7PtuFhYam4EXpX/F+51kv6R7EbEZ/8LP3/vuw3PcfhS/uONpIMk3STpDkm3SHpBvv74cy9WSPoHSdfmY/wvzJfvKuk7km6VtFZSpxGNDweeiYgLxhdExO0RcaMyn8xbSmslndiQ+3pJX5Z0n6S/kXRKnnOtpFfm610i6QJJN+brLciX7yTpC/m6t0k6PF/+HklXSPpm/p3+z3gmSX8g6d/y7/WVfGwxJP1Q0pkN33cfZQNULgH+PG/p/U6P/1vaNDJcdQCzccqGlj4K+Ga+6GDg9fkQys0OJBuLfxPwr8BvS7oF+CfgxIhYo2wI7ydbfHY/smeC7ALcJunrZGPmHBcRj0vaHbhZ0upof9fq64F2gxm+HTiA7PkSuwNrJN2Qv7c/8FqyoaQ3ABdFxMHKHmb1AeC0fL05wKHAK4HrJL0KWAYQEb8laR/gmobTXgfkx+QpYJ2kc/Lv/j+B34uIX0j6KPAh4OP5Zx6NiHmSlpLdCf9+SRcA/xkRf9vmu1lNuVhYCn5D0u356xvJxsA6BLilTaEgf28jQP7ZOcBjwMMRsQZgfFTevNHR6GsR8STwpKTryIrS14G/kvRmsuFUZpOdUvr3At/nTcClEbGVbCC364GDgMeBNeNDRkv6AXBN/pm1ZK2VcV+OiF8D90vaAOyTb/ec/Lt9X9KPgPFi8Z2IeCzf7j3Ay4HdyB4U9q/5MdgR+LeGfYwPRjlGVuDM2nKxsBQ8GREHNC7If9x+McFnnmp4vZXs/8uiu2Hrm9cJ4BRgBjA/Ip5RNqrtThNs427g+DbvtRr+eVxj7l83zP+a7f89tsrY7XYbj8e3I+LkDp8ZX9+sLfdZ2HTyfWCWpIMA8v6KVj+Cx+bn/19K1qG7BngR2XMynsn7Al7eYV/XAs8f7/PI93eQpEOBG4ATlT0nfAbZ0+wmHNGzhRMk7ZD3Y7wCWJdv95R8X68mGxxu3QTbuJns9Nyr8s/s3MXVWk8AL5hkVqsBFwubNvLH7Z4InCPpDuDbtG4d3EJ22ulm4KyI2AR8CRiRNEr2g/z9DvsK4Djg95VdOns3sIKsD+WrwJ3AHWRF5SP5cOKTsQ64HvgGsCQifgWcDwxJWkvWN/OeiHiq3QYiYjPwHuBSSXfm33efDvu9EjjOHdzWzKPOWq1IWkHiHbiSLgGuiojLq85iNs4tCzMz68gtCzMz68gtCzMz68jFwszMOnKxMDOzjlwszMysIxcLMzPr6P8D2wZcJL9hpTEAAAAASUVORK5CYII=","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["#compute cumulative variance of the principal components\n","cum_var=len(pca.explained_variance_ratio_)*[0]\n","cum_var[0]=pca.explained_variance_ratio_[0]\n","for i in range(1,len(cum_var)):\n","    cum_var[i]=cum_var[i-1]+pca.explained_variance_ratio_[i]\n","\n","#plot it\n","fig = plt.figure(figsize=(6, 4))\n","ax = fig.gca()\n","\n","ax.plot(np.arange(1, len(pca.explained_variance_) + 1), cum_var, 'ok', markersize=2)\n","ax.axvline(10, linestyle=\"dashed\", color=\"red\", linewidth=1)\n","ax.axvline(20, linestyle=\"dashed\", color=\"red\", linewidth=1)\n","plt.xlim(0, 100)\n","\n","ax.set_xlabel(\"Principal Component\")\n","ax.set_ylabel(\"Explained Variance\");"]},{"cell_type":"markdown","id":"1d27aba9","metadata":{"id":"1d27aba9"},"source":["From the explained variance ratio plot, I think we should be willing to try with something between 10 and 20 PCs"]},{"cell_type":"markdown","id":"2d08a9d4","metadata":{"id":"2d08a9d4"},"source":["#### 2.2 Elbow method"]},{"cell_type":"code","execution_count":null,"id":"a8a163ea","metadata":{"id":"a8a163ea","outputId":"7da26555-2710-4aef-c07c-ea97b0f81ecc"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["fig = plt.figure(figsize=(6, 4))\n","ax = fig.gca()\n","\n","ax.plot(np.arange(1, len(pca.explained_variance_) + 1), pca.explained_variance_, 'ok', markersize=2)\n","ax.axvline(20, linestyle=\"dashed\", color=\"red\", linewidth=1)\n","plt.xlim(0, 100)\n","\n","ax.set_xlabel(\"Principal Component\")\n","ax.set_ylabel(\"Explained Variance\");"]},{"cell_type":"markdown","id":"f007172b","metadata":{"id":"f007172b"},"source":["The elbow method suggests around 20 PCs. Therefore, I am going to run method number 3 but considering as candidates around 20 components because trying more combinations will take a lot of time."]},{"cell_type":"markdown","id":"1f9c4587","metadata":{"id":"1f9c4587"},"source":["#### 2.3 Cross-Validation PCA"]},{"cell_type":"markdown","id":"11b4410d","metadata":{"id":"11b4410d"},"source":["To do that, PCA will be considered as part of model training rather than data preprocessing. I defined a pipeline that consits on: scale data, apply PCA and finally apply a classification model. The pipeline parameters will be the number of principal components and the classifier parameters. After determining the best paraemters throguh cross-validation I will evaluate the test set with these aprameters. This can be easily implemented with Pipeline() and GridSearchCV().\n","\n","The methods I tried were:\n","- KNN (data-based)\n","- Logistic regressoin(model-based discriminative)\n","- Discriminant Analysis(model-based generative)\n","\n","Other classification methods that we could try if we had more time could be SVM (model-based discriminative), and random forests, which are based on the concept of partitioning."]},{"cell_type":"markdown","id":"02005167","metadata":{"id":"02005167"},"source":["##### 2.3.1 K nearest neighbors\n","The only assumption is that the closer 2 points the more similar they are. However the notion of distance breaks down in high dimensioanl spaces, that is why PCA can be very useful. I will be using the default distance metric implemented in python: Euclidean distance.\n","\n","Also, note that we chose to cross-validate with 10 folds because it is a standard number, and the GridSearchCV score (which is the score used to select the best parameters) will be the balanced accuracy, a type of accuracy that performs better in unblanced datasets like our dataset"]},{"cell_type":"code","execution_count":null,"id":"1ff40cfe","metadata":{"id":"1ff40cfe","outputId":"8b93fc34-dd1f-49fa-c72d-43ac7a773fca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters obtained from Grid Search:\n"," {'knn__n_neighbors': 1, 'reduce_dims__n_components': 30}\n"]}],"source":["#Cross-validation pipeline of Standarize + PCA + KNN\n","pipe = Pipeline([(\"scale\", StandardScaler()),\n","                 (\"reduce_dims\", PCA()),\n","                 (\"knn\", KNeighborsClassifier())])\n","\n","#parameters to try\n","param_grid = dict(reduce_dims__n_components = [15,20,25,30], #decided from previous section\n","                  knn__n_neighbors=[1,3,5,7,9]) #standard values to try\n","\n","#perform cross validation in the given pipelin\n","grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, scoring=\"balanced_accuracy\")\n","grid.fit(X_train, y_train)\n","\n","print('Best parameters obtained from Grid Search:\\n', grid.best_params_)"]},{"cell_type":"markdown","id":"69cfd3ed","metadata":{"id":"69cfd3ed"},"source":["Classification report test set"]},{"cell_type":"code","execution_count":null,"id":"c7f8811b","metadata":{"id":"c7f8811b","outputId":"164d7f80-0f6e-4d21-a64e-01be5024556b"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.99      0.99      0.99       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      1.00      1.00       111\n","          LU       0.98      0.97      0.98       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.77      0.83      0.80        12\n","\n","    accuracy                           0.99       578\n","   macro avg       0.96      0.97      0.96       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["grid_predictions = grid.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, grid_predictions))"]},{"cell_type":"markdown","id":"dcf692eb","metadata":{"id":"dcf692eb"},"source":["##### 2.3.2 Logistic Regression\n","Uses the similarity of the logistic function with the standard normal CDF to classify the data after applying a linear transformation to it. If its greater than 0.5 it will be to class 1, lower it will belong to the otehr class. This is, a model approximation for p(i|x). The original model is for binary classification but it can be extended to multi class.\n","\n","Assumptions:\n","- Binary classification (extended to multiclass using softmax)\n","- No multicollinearity (reduced with PCA)\n","- Large sample (sample of 2000)\n","- Linear relationshiip of variables to log odds (to be tested)\n","- No outliers (to be tested)\n","- Independent oservations (to be tested)"]},{"cell_type":"code","execution_count":null,"id":"10cbdb44","metadata":{"id":"10cbdb44","outputId":"fae99114-ed91-4f2f-cbad-74d15b73f295"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters obtained from Grid Search:\n"," {'reduce_dims__n_components': 30}\n"]}],"source":["#Cross-validation pipeline of Standarize + PCA + Logistic\n","pipe = Pipeline([(\"scale\", StandardScaler()),\n","                 (\"reduce_dims\", PCA()),\n","                 (\"logistic\", LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000))])\n","\n","#parameters to try\n","param_grid = dict(reduce_dims__n_components = [15,20,25,30])\n","\n","#cross-validation in our pipeline\n","logistic_grid = GridSearchCV(pipe, param_grid=param_grid, cv=10, scoring=\"balanced_accuracy\") #perform cross validation in the given pipelin\n","logistic_grid.fit(X_train, y_train)\n","\n","print('Best parameters obtained from Grid Search:\\n', logistic_grid.best_params_)"]},{"cell_type":"markdown","id":"439f337b","metadata":{"id":"439f337b"},"source":["Classification report test set"]},{"cell_type":"code","execution_count":null,"id":"4a95628d","metadata":{"id":"4a95628d","outputId":"3097abe3-11dc-42a3-8676-7b48547475b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.99      1.00      0.99       251\n","         GBM       0.97      1.00      0.99        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.98      0.99       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.92      0.92      0.92        12\n","\n","    accuracy                           0.99       578\n","   macro avg       0.98      0.98      0.98       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["logistic_grid_predictions = logistic_grid.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, logistic_grid_predictions))"]},{"cell_type":"markdown","id":"619320ce","metadata":{"id":"619320ce"},"source":["##### 2.3.3 Quadratic Discriminant Analysis\n","Finally, we use QDA (the more flexible discriminant analysis) to model p(x,i) assuming that p(x|i) is normal and estimating the prior p(i) from the data.\n","\n","Assumptions:\n","- p(x|i) ~ Normal (should be tested)\n","- QDA assumes that each class has its own covariance matrix"]},{"cell_type":"code","execution_count":null,"id":"a40d2cb8","metadata":{"id":"a40d2cb8","outputId":"164a2f00-ddb4-4dfd-c6da-0d64b269100e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters obtained from Grid Search:\n"," {'reduce_dims__n_components': 20}\n"]}],"source":["#Cross-validation pipeline of Standarize + PCA + QDA\n","pipe = Pipeline([(\"scale\", StandardScaler()),\n","                 (\"reduce_dims\", PCA()),\n","                 (\"logistic\", QuadraticDiscriminantAnalysis())])\n","\n","#parameter definition\n","param_grid = dict(reduce_dims__n_components = [15,20,25,30])\n","\n","#pipeline training\n","grid = GridSearchCV(pipe, param_grid=param_grid, cv=10) #perform cross validation in the given pipelin\n","grid.fit(X_train, y_train)\n","\n","print('Best parameters obtained from Grid Search:\\n', grid.best_params_)"]},{"cell_type":"markdown","id":"5c2af188","metadata":{"id":"5c2af188"},"source":["Classification report test set"]},{"cell_type":"code","execution_count":null,"id":"c278b903","metadata":{"id":"c278b903","outputId":"05b8f0bb-44b7-4ec0-a710-42cf8eb628c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       1.00      0.99      0.99       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      1.00      1.00       111\n","          LU       0.99      0.98      0.99       116\n","          OV       0.98      1.00      0.99        53\n","           U       0.85      0.92      0.88        12\n","\n","    accuracy                           0.99       578\n","   macro avg       0.97      0.98      0.98       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["grid_predictions = grid.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, grid_predictions))"]},{"cell_type":"markdown","id":"fb14a9d2","metadata":{"id":"fb14a9d2"},"source":["##### 2.3.4 Conclusion"]},{"cell_type":"markdown","id":"ae81d064","metadata":{"id":"ae81d064"},"source":["In conclusion, we tested 3 different type of classification algortihms: knn, logistic regression and QDA. Overall the three models work quite good, being logistic regression the one that performs best overall (in some runs Knn was slighlty better but after running everything several times ther was a clear tendency for logistic regression to be better).\n","\n","The most flexible model was knn, which only assumed similarity between close data points, while logistic regression can be\n","considered the most restrictive, as it had more assumptions on the model. On the other hand QDA had fewer assumptions, but stronger to meet."]},{"cell_type":"markdown","id":"025cb047","metadata":{"id":"025cb047"},"source":["Logistic regression with no PCA"]},{"cell_type":"code","execution_count":null,"id":"e9c29fc7","metadata":{"id":"e9c29fc7","outputId":"d83346ce-6108-4bb8-bdf4-9ad1f409b812"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       1.00      1.00      1.00       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.99      1.00       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.86      1.00      0.92        12\n","\n","    accuracy                           1.00       578\n","   macro avg       0.98      1.00      0.99       578\n","weighted avg       1.00      1.00      1.00       578\n","\n"]}],"source":["logr = LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000)\n","logr.fit(X_train,y_train)\n","\n","#predict if tumor is cancerous where the size is 3.46mm:\n","predicted = logr.predict(X_test)\n","print(classification_report(y_test, predicted))"]},{"cell_type":"markdown","id":"5389fb9b","metadata":{"id":"5389fb9b"},"source":["Logistic Regression PCA"]},{"cell_type":"code","execution_count":null,"id":"4761140b","metadata":{"id":"4761140b","outputId":"0920f1f6-28e6-4346-844d-66f2409887c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.99      1.00      0.99       251\n","         GBM       0.97      1.00      0.99        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.98      0.99       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.92      0.92      0.92        12\n","\n","    accuracy                           0.99       578\n","   macro avg       0.98      0.98      0.98       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["print(classification_report(y_test, logistic_grid_predictions))"]},{"cell_type":"markdown","id":"8324be4d","metadata":{"id":"8324be4d"},"source":["Additionally, we can see that if we don't apply the PCA the model performs slightly better (in the order of 0.01), which I think we should use in this case as there are not many samples. However, as the number of samples increases applying PCA could be very useful to reduce computation time and avoid some spurious correlations, as the results obtained applying PCA are almost identical, but simplify the dataset quite a bit."]},{"cell_type":"markdown","id":"ac2e8ecd","metadata":{"id":"ac2e8ecd"},"source":["### 3. Cross-Validation Feature Selection"]},{"cell_type":"markdown","id":"1a4346b8","metadata":{"id":"1a4346b8"},"source":["In this section I am going to make the same than before but instead of reducing dimensions using PCA, I will focus on a smart feature selection, that is features with maximum variance, features that correlate more with the response (ANOVA F-score) and recursive feature elimination. Other well-known techniques are recursive feature selection, Mutual Information Entropy, variable importance with random forests and Lasso regression. The methods applied come from the sklearn.feature_selection library.\n","\n","I only applied it to logistic regression so I could focus on studying the different techniques deeper."]},{"cell_type":"markdown","id":"8d6c74ff","metadata":{"id":"8d6c74ff"},"source":["#### 3.1 Removing features with maximum variance"]},{"cell_type":"markdown","id":"d4368dc3","metadata":{"id":"d4368dc3"},"source":["First of all I plotted the variance of each feature to get and idea."]},{"cell_type":"code","execution_count":null,"id":"4243c3a7","metadata":{"id":"4243c3a7","outputId":"fd429e48-3ddf-4c38-d967-2e7594f5dde4"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Plotting a basic histogram\n","var= X_train.var(axis='rows')\n","\n","plt.hist(var, bins=200, color='skyblue', edgecolor='black')\n","\n","# Adding labels and title\n","plt.xlabel('Values')\n","plt.ylabel('Frequency')\n","plt.title('Basic Histogram')\n","\n","# Display the plot\n","plt.show()"]},{"cell_type":"markdown","id":"8e8b05df","metadata":{"id":"8e8b05df"},"source":["Overall this plot reminds a bit to the PCA plot: most of the features are not very important in terms of variance. Also I realized that we have some features with 0 variance, which means that all the values are the same so they can be removed. I think that  a good starting point is removing these majority of features with lower variance (around 5)."]},{"cell_type":"code","execution_count":null,"id":"b433bc7f","metadata":{"id":"b433bc7f","outputId":"582b9b1c-2fe8-436b-dbe5-0a12b5ab1342"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters obtained from Grid Search:\n"," {'feature_selection__threshold': 0}\n"]}],"source":["#Cross-validation pipeline\n","pipe = Pipeline([\n","    ('feature_selection', VarianceThreshold()),\n","    (\"logistic\", LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000))\n","])\n","\n","#variance threshold (0,5,7,10)\n","param_grid = dict(feature_selection__threshold=[0,5,7,10])\n","\n","#cross validation for the different variance thresholds\n","grid = GridSearchCV(pipe, param_grid=param_grid, cv=10,scoring=\"balanced_accuracy\")\n","#cross validation for threshold=10\n","grid2 = GridSearchCV(pipe, param_grid=dict(feature_selection__threshold=[7]) , cv=10,scoring=\"balanced_accuracy\" ) #perfosrm cross validation in the given pipelin\n","\n","#fit the 2 grids\n","grid.fit(X_train, y_train)\n","grid2.fit(X_train, y_train)\n","\n","print('Best parameters obtained from Grid Search:\\n', grid.best_params_)"]},{"cell_type":"markdown","id":"fc639a82","metadata":{"id":"fc639a82"},"source":["In the obtained results we can see that, similar to the PCA case, the most predictive power is in only removing the constant features (variance threshold=0). However, for the same reasons as before we decided to print the results of the grid training and observe that the mean_test_score is of 0.99, but when chosing a threshold of 7 the score is of 0.98, which means that removing most of the features we can get very similar prediciton power."]},{"cell_type":"code","execution_count":null,"id":"3a6ac05a","metadata":{"id":"3a6ac05a","outputId":"36783c07-38f6-4657-f38e-e209cc0ce9bd"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_fit_time</th>\n","      <th>std_fit_time</th>\n","      <th>mean_score_time</th>\n","      <th>std_score_time</th>\n","      <th>param_feature_selection__threshold</th>\n","      <th>params</th>\n","      <th>split0_test_score</th>\n","      <th>split1_test_score</th>\n","      <th>split2_test_score</th>\n","      <th>split3_test_score</th>\n","      <th>split4_test_score</th>\n","      <th>split5_test_score</th>\n","      <th>split6_test_score</th>\n","      <th>split7_test_score</th>\n","      <th>split8_test_score</th>\n","      <th>split9_test_score</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.423838</td>\n","      <td>0.194941</td>\n","      <td>0.015447</td>\n","      <td>0.001170</td>\n","      <td>0</td>\n","      <td>{'feature_selection__threshold': 0}</td>\n","      <td>0.996296</td>\n","      <td>1.000000</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.996599</td>\n","      <td>0.994641</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>0.996296</td>\n","      <td>0.998043</td>\n","      <td>0.002025</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.405702</td>\n","      <td>0.042397</td>\n","      <td>0.013419</td>\n","      <td>0.005046</td>\n","      <td>5</td>\n","      <td>{'feature_selection__threshold': 5}</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.988662</td>\n","      <td>0.942033</td>\n","      <td>0.992063</td>\n","      <td>0.964948</td>\n","      <td>1.0</td>\n","      <td>0.986642</td>\n","      <td>0.987095</td>\n","      <td>0.018179</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.405449</td>\n","      <td>0.044456</td>\n","      <td>0.015924</td>\n","      <td>0.012352</td>\n","      <td>7</td>\n","      <td>{'feature_selection__threshold': 7}</td>\n","      <td>1.000000</td>\n","      <td>0.994863</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.955329</td>\n","      <td>0.942033</td>\n","      <td>0.958730</td>\n","      <td>0.966667</td>\n","      <td>1.0</td>\n","      <td>0.986642</td>\n","      <td>0.980086</td>\n","      <td>0.021026</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.416780</td>\n","      <td>0.044111</td>\n","      <td>0.015095</td>\n","      <td>0.002340</td>\n","      <td>10</td>\n","      <td>{'feature_selection__threshold': 10}</td>\n","      <td>0.996296</td>\n","      <td>0.993126</td>\n","      <td>0.953196</td>\n","      <td>0.950758</td>\n","      <td>0.991461</td>\n","      <td>0.942033</td>\n","      <td>0.950794</td>\n","      <td>0.964948</td>\n","      <td>1.0</td>\n","      <td>0.937038</td>\n","      <td>0.967965</td>\n","      <td>0.023369</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n","0       1.423838      0.194941         0.015447        0.001170   \n","1       0.405702      0.042397         0.013419        0.005046   \n","2       0.405449      0.044456         0.015924        0.012352   \n","3       0.416780      0.044111         0.015095        0.002340   \n","\n","  param_feature_selection__threshold                                params  \\\n","0                                  0   {'feature_selection__threshold': 0}   \n","1                                  5   {'feature_selection__threshold': 5}   \n","2                                  7   {'feature_selection__threshold': 7}   \n","3                                 10  {'feature_selection__threshold': 10}   \n","\n","   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n","0           0.996296           1.000000           0.996599           1.000000   \n","1           1.000000           1.000000           0.996599           1.000000   \n","2           1.000000           0.994863           0.996599           1.000000   \n","3           0.996296           0.993126           0.953196           0.950758   \n","\n","   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n","0           0.996599           0.994641           1.000000           1.000000   \n","1           0.988662           0.942033           0.992063           0.964948   \n","2           0.955329           0.942033           0.958730           0.966667   \n","3           0.991461           0.942033           0.950794           0.964948   \n","\n","   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n","0                1.0           0.996296         0.998043        0.002025   \n","1                1.0           0.986642         0.987095        0.018179   \n","2                1.0           0.986642         0.980086        0.021026   \n","3                1.0           0.937038         0.967965        0.023369   \n","\n","   rank_test_score  \n","0                1  \n","1                2  \n","2                3  \n","3                4  "]},"execution_count":164,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(grid.cv_results_)"]},{"cell_type":"markdown","id":"69498adc","metadata":{"id":"69498adc"},"source":["Test score of Variance Threshold 0"]},{"cell_type":"code","execution_count":null,"id":"8ebe70f5","metadata":{"id":"8ebe70f5","outputId":"9ccc8bff-8737-46ce-ed66-8023ba81ef66"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       1.00      1.00      1.00       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.99      1.00       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.86      1.00      0.92        12\n","\n","    accuracy                           1.00       578\n","   macro avg       0.98      1.00      0.99       578\n","weighted avg       1.00      1.00      1.00       578\n","\n"]}],"source":["grid_predictions = grid.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, grid_predictions))"]},{"cell_type":"markdown","id":"0eadc18e","metadata":{"id":"0eadc18e"},"source":["Test score of Variance Threshold 7"]},{"cell_type":"code","execution_count":null,"id":"202749b5","metadata":{"id":"202749b5","outputId":"1327cdf4-51d4-4dbb-b395-31909547e4de"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.99      1.00      0.99       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      0.99      1.00       111\n","          LU       1.00      0.99      1.00       116\n","          OV       0.98      1.00      0.99        53\n","           U       0.83      0.83      0.83        12\n","\n","    accuracy                           0.99       578\n","   macro avg       0.97      0.97      0.97       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["grid_predictions2 = grid2.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, grid_predictions2))"]},{"cell_type":"markdown","id":"a64f0e20","metadata":{"id":"a64f0e20"},"source":["As said, the difference between removing none of the features and most of the features is very small, so even though with this dataset it would be okay to not remove anything, we have proven that as it gets bigger and complex we would be able to make it much more simpler in order to get a siginificant predictive power * move to conlcusion*"]},{"cell_type":"markdown","id":"58dc18c8","metadata":{"id":"58dc18c8"},"source":["#### 3.2 Keeping features with ANOVA F-Score\n","We computed and ANOVA F-test of each feature and select the top scoring percentile features. ANOVA is a parametric statistical technique for assessing if two means come from the same disgribution. The F-statistic is obtained computing the ration between observed variances of normal distribution. In this case, the score is obtained comparing the variances of each feature with respect to the target variable."]},{"cell_type":"code","execution_count":null,"id":"88ac2c25","metadata":{"id":"88ac2c25","outputId":"016881a5-e4eb-49e8-d7dc-6b723621e05b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best parameters obtained from Grid Search:\n"," {'feature_selection__percentile': 80}\n"]}],"source":["#Cross-validation pipeline\n","pipe = Pipeline([\n","    ('feature_selection0', VarianceThreshold(threshold=0)), #remove contstant features in order to perform F-test\n","    ('feature_selection', SelectPercentile(f_classif)),\n","    (\"logistic\", LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000))\n","])\n","\n","#the percentile indicates which % of features we keep\n","param_grid = dict(feature_selection__percentile=[5,20,40,60,80,100])\n","\n","#apply cross-validation\n","grid_fscore = GridSearchCV(pipe, param_grid=param_grid, cv=10, scoring=\"balanced_accuracy\")\n","grid_fscore.fit(X_train, y_train)\n","\n","#cross validation for percentile=5%\n","grid2_fscore = GridSearchCV(pipe, param_grid=dict(feature_selection__percentile=[5]) , cv=10,scoring=\"balanced_accuracy\" ) #perfosrm cross validation in the given pipelin\n","grid2_fscore.fit(X_train, y_train)\n","\n","print('Best parameters obtained from Grid Search:\\n', grid_fscore.best_params_)"]},{"cell_type":"code","execution_count":null,"id":"5962d32a","metadata":{"id":"5962d32a","outputId":"f6ee0767-9a8d-42bf-ae07-c6abf7fd45b5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_fit_time</th>\n","      <th>std_fit_time</th>\n","      <th>mean_score_time</th>\n","      <th>std_score_time</th>\n","      <th>param_feature_selection__percentile</th>\n","      <th>params</th>\n","      <th>split0_test_score</th>\n","      <th>split1_test_score</th>\n","      <th>split2_test_score</th>\n","      <th>split3_test_score</th>\n","      <th>split4_test_score</th>\n","      <th>split5_test_score</th>\n","      <th>split6_test_score</th>\n","      <th>split7_test_score</th>\n","      <th>split8_test_score</th>\n","      <th>split9_test_score</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","      <th>rank_test_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.379558</td>\n","      <td>0.055583</td>\n","      <td>0.012066</td>\n","      <td>0.006105</td>\n","      <td>5</td>\n","      <td>{'feature_selection__percentile': 5}</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>0.954932</td>\n","      <td>0.954932</td>\n","      <td>0.996599</td>\n","      <td>0.994641</td>\n","      <td>0.992063</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.994578</td>\n","      <td>0.988774</td>\n","      <td>0.017131</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.394392</td>\n","      <td>0.033392</td>\n","      <td>0.012737</td>\n","      <td>0.004593</td>\n","      <td>20</td>\n","      <td>{'feature_selection__percentile': 20}</td>\n","      <td>0.996296</td>\n","      <td>1.0</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.996599</td>\n","      <td>0.983303</td>\n","      <td>0.992063</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.996296</td>\n","      <td>0.996116</td>\n","      <td>0.004914</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.646803</td>\n","      <td>0.084624</td>\n","      <td>0.016695</td>\n","      <td>0.004646</td>\n","      <td>40</td>\n","      <td>{'feature_selection__percentile': 40}</td>\n","      <td>0.996296</td>\n","      <td>1.0</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.988662</td>\n","      <td>0.994641</td>\n","      <td>0.992063</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.994578</td>\n","      <td>0.996284</td>\n","      <td>0.003699</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.894305</td>\n","      <td>0.154391</td>\n","      <td>0.012725</td>\n","      <td>0.006476</td>\n","      <td>60</td>\n","      <td>{'feature_selection__percentile': 60}</td>\n","      <td>0.996296</td>\n","      <td>1.0</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.996599</td>\n","      <td>0.994641</td>\n","      <td>0.992063</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.996296</td>\n","      <td>0.997249</td>\n","      <td>0.002581</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.302057</td>\n","      <td>0.181233</td>\n","      <td>0.014879</td>\n","      <td>0.001397</td>\n","      <td>80</td>\n","      <td>{'feature_selection__percentile': 80}</td>\n","      <td>0.996296</td>\n","      <td>1.0</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.996599</td>\n","      <td>0.994641</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.996296</td>\n","      <td>0.998043</td>\n","      <td>0.002025</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.168599</td>\n","      <td>0.145657</td>\n","      <td>0.014821</td>\n","      <td>0.005199</td>\n","      <td>100</td>\n","      <td>{'feature_selection__percentile': 100}</td>\n","      <td>0.996296</td>\n","      <td>1.0</td>\n","      <td>0.996599</td>\n","      <td>1.000000</td>\n","      <td>0.996599</td>\n","      <td>0.994641</td>\n","      <td>1.000000</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.996296</td>\n","      <td>0.998043</td>\n","      <td>0.002025</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n","0       0.379558      0.055583         0.012066        0.006105   \n","1       0.394392      0.033392         0.012737        0.004593   \n","2       0.646803      0.084624         0.016695        0.004646   \n","3       0.894305      0.154391         0.012725        0.006476   \n","4       1.302057      0.181233         0.014879        0.001397   \n","5       1.168599      0.145657         0.014821        0.005199   \n","\n","  param_feature_selection__percentile                                  params  \\\n","0                                   5    {'feature_selection__percentile': 5}   \n","1                                  20   {'feature_selection__percentile': 20}   \n","2                                  40   {'feature_selection__percentile': 40}   \n","3                                  60   {'feature_selection__percentile': 60}   \n","4                                  80   {'feature_selection__percentile': 80}   \n","5                                 100  {'feature_selection__percentile': 100}   \n","\n","   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n","0           1.000000                1.0           0.954932           0.954932   \n","1           0.996296                1.0           0.996599           1.000000   \n","2           0.996296                1.0           0.996599           1.000000   \n","3           0.996296                1.0           0.996599           1.000000   \n","4           0.996296                1.0           0.996599           1.000000   \n","5           0.996296                1.0           0.996599           1.000000   \n","\n","   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n","0           0.996599           0.994641           0.992063                1.0   \n","1           0.996599           0.983303           0.992063                1.0   \n","2           0.988662           0.994641           0.992063                1.0   \n","3           0.996599           0.994641           0.992063                1.0   \n","4           0.996599           0.994641           1.000000                1.0   \n","5           0.996599           0.994641           1.000000                1.0   \n","\n","   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n","0                1.0           0.994578         0.988774        0.017131   \n","1                1.0           0.996296         0.996116        0.004914   \n","2                1.0           0.994578         0.996284        0.003699   \n","3                1.0           0.996296         0.997249        0.002581   \n","4                1.0           0.996296         0.998043        0.002025   \n","5                1.0           0.996296         0.998043        0.002025   \n","\n","   rank_test_score  \n","0                6  \n","1                5  \n","2                4  \n","3                3  \n","4                1  \n","5                1  "]},"execution_count":178,"metadata":{},"output_type":"execute_result"}],"source":["pd.DataFrame(grid_fscore.cv_results_)"]},{"cell_type":"markdown","id":"39a68af3","metadata":{"id":"39a68af3"},"source":["Test score for percentile of 80%"]},{"cell_type":"code","execution_count":null,"id":"519f5545","metadata":{"id":"519f5545","outputId":"a1e88e5d-b9de-4823-8354-230cdb7442a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       1.00      1.00      1.00       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.99      1.00       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.86      1.00      0.92        12\n","\n","    accuracy                           1.00       578\n","   macro avg       0.98      1.00      0.99       578\n","weighted avg       1.00      1.00      1.00       578\n","\n"]}],"source":["grid_fscore_predictions = grid_fscore.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, grid_fscore_predictions))"]},{"cell_type":"markdown","id":"db6d9e05","metadata":{"id":"db6d9e05"},"source":["Test score for percentile of 5%"]},{"cell_type":"code","execution_count":null,"id":"5715a565","metadata":{"id":"5715a565","outputId":"084db2fd-b020-4cd7-974f-b7cf5ef3d9ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.99      1.00      1.00       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      0.99      1.00       111\n","          LU       1.00      0.98      0.99       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.92      1.00      0.96        12\n","\n","    accuracy                           0.99       578\n","   macro avg       0.99      1.00      0.99       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["grid_fscore_predictions2 = grid2_fscore.predict(X_test)\n","\n","# print classification report\n","print(classification_report(y_test, grid_fscore_predictions2))"]},{"cell_type":"markdown","id":"205d8c71","metadata":{"id":"205d8c71"},"source":["Compared to the previous case, when we make a feature selection based on F-score the results get even better. In this case the balanced_accuracy score of GridSearchCV chose 80% of the features as a better predictor than keeping everything. However, when we only keep the top 5% of the features we managed to get a 0.98 of mean test score and a very good classification report. Performing feature selection with f-score gets the same level of results than applying logistic regression to all the data, and also beats PCA."]},{"cell_type":"markdown","id":"49145ac7","metadata":{"id":"49145ac7"},"source":["#### 3.3 Recursive Feature Elimination (to do)"]},{"cell_type":"code","execution_count":null,"id":"b2fe89ce","metadata":{"id":"b2fe89ce"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"8c4d9046","metadata":{"id":"8c4d9046"},"source":["#### 3.4 Conclusion"]},{"cell_type":"markdown","id":"a642688f","metadata":{"id":"a642688f"},"source":["After applying 3 different feature selction techniques we concluded that selecting features based on f-score is the best method. Selecting features based on variance (as well as PCA) did not improve results compared to applying raw logistic regression, but they have been proven to be very useful to achieve very similar results (in the order of 0.01 difference) which means that any of these methods should definitely be applied as the dataset grows both on p and n.\n","\n","On the other hand keeping 80% of the features through f-score we were able to not only beat all the other methods, but also the raw logisitic regression applied to the entire dataset. Moreover, we were able to keep the same level of significant results even when keeping only 5% of the feaatures, which would help to simplify the dataset significantly more than any of the other methods.\n","\n","See below a summary of Raw logistic regression, PCA logistic regression and F-score logistic regression."]},{"cell_type":"markdown","id":"f66f85aa","metadata":{"id":"f66f85aa"},"source":["PCA Logistic Regreession"]},{"cell_type":"code","execution_count":null,"id":"b6c490c4","metadata":{"id":"b6c490c4","outputId":"5bc9d1b0-6e91-4f15-cb29-05599ab1ca01"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.99      1.00      0.99       251\n","         GBM       0.97      1.00      0.99        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.98      0.99       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.92      0.92      0.92        12\n","\n","    accuracy                           0.99       578\n","   macro avg       0.98      0.98      0.98       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["print(classification_report(y_test, logistic_grid_predictions))"]},{"cell_type":"markdown","id":"adcbb6d8","metadata":{"id":"adcbb6d8"},"source":["Raw Logistic Regression"]},{"cell_type":"code","execution_count":null,"id":"76a12e1e","metadata":{"id":"76a12e1e","outputId":"61d494f4-74ee-492c-db4e-b82bed3d686f"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       1.00      1.00      1.00       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.99      1.00       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.86      1.00      0.92        12\n","\n","    accuracy                           1.00       578\n","   macro avg       0.98      1.00      0.99       578\n","weighted avg       1.00      1.00      1.00       578\n","\n"]}],"source":["#predict if tumor is cancerous where the size is 3.46mm:\n","predicted = logr.predict(X_test)\n","print(classification_report(y_test, predicted))"]},{"cell_type":"markdown","id":"2f2800b6","metadata":{"id":"2f2800b6"},"source":["F-score Logistic Regression"]},{"cell_type":"code","execution_count":null,"id":"58dc5854","metadata":{"id":"58dc5854","outputId":"f6db1c18-2310-4256-80be-3d51dfd1eb99"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       1.00      1.00      1.00       251\n","         GBM       1.00      1.00      1.00        35\n","          KI       1.00      1.00      1.00       111\n","          LU       1.00      0.99      1.00       116\n","          OV       1.00      1.00      1.00        53\n","           U       0.86      1.00      0.92        12\n","\n","    accuracy                           1.00       578\n","   macro avg       0.98      1.00      0.99       578\n","weighted avg       1.00      1.00      1.00       578\n","\n"]}],"source":["print(classification_report(y_test, grid_fscore_predictions))"]},{"cell_type":"markdown","id":"094377eb","metadata":{"id":"094377eb"},"source":["### 4. Different trainning sizes (to do)"]},{"cell_type":"markdown","id":"45494b6d","metadata":{"id":"45494b6d"},"source":["In this section we will study the effect of different train,test split size on the model performance. We will only focus on the best performance model: Logistic Regression with feature selection based on f-score."]},{"cell_type":"code","execution_count":null,"id":"f16b37b0","metadata":{"id":"f16b37b0"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"6f8bee6b","metadata":{"id":"6f8bee6b"},"source":["#### 4.1 Conclusion\n","..."]},{"cell_type":"markdown","id":"572b8615","metadata":{"id":"572b8615"},"source":["### 5. Optional Questions (review)"]},{"cell_type":"markdown","id":"8fd83cdd","metadata":{"id":"8fd83cdd"},"source":["**Can you construct a data set where PCA dimension reduction should improve classification performance?**\n","\n","A dataset where feature 1 is x, feature 2 is x^2, ..., feature n x^n, and classes related to the value of x. Raw training could result in spurious correlations as all the rows fundamentally depend on x and they don't provide anything new. I think that in this case PCA would help a lot detcting this dependencies among the data.\n","\n","**Can you construct a data set where PCA dimension reduction should reduce classification performance?**\n","\n","Imagine a dataset with 5 features, where they are all 0 except 1 of the features, and 5 classes where it will belong to the class in which it has a 1. Doing a PCA won't have any effect as the rows are already orthogonal to each other. However, removing information will result in a fundamental loss information that will produce missclassficiation no matter how much you train the model."]},{"cell_type":"markdown","id":"47462b13","metadata":{"id":"47462b13"},"source":["## Theme 1: Misslabelling"]},{"cell_type":"code","execution_count":3,"id":"cd8b591f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":875,"status":"error","timestamp":1712862893309,"user":{"displayName":"Francisco Boudagh","userId":"17739828160985964623"},"user_tz":-120},"id":"cd8b591f","outputId":"909cf6b4-59c1-4db3-c219-ec5c6d54efdf"},"outputs":[],"source":["# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n","\n","mislabel=[0.1, 0.25, 0.85] #% of data modified\n","clases=['BC','KI','LU','OV','GBM','U']\n","\n","light_mislabel=y_train.copy() #10% of data modified\n","mid_mislabel=y_train.copy() #25% of data modified\n","hard_mislabel=y_train.copy() #%85 of data modified\n","\n","#apply misslabelling using random\n","for i in range(hard_mislabel.size):\n","    number=random.uniform(0,1)\n","    if number<mislabel[2]:\n","        hard_mislabel.iloc[i]= random.choice(clases)\n","\n","        if number<mislabel[1]:\n","            mid_mislabel.iloc[i] = random.choice(clases)\n","\n","            if number<mislabel[0]:\n","                light_mislabel.iloc[i]= random.choice(clases)\n"]},{"cell_type":"markdown","id":"bf3b7dd3","metadata":{"id":"bf3b7dd3"},"source":["### 6. Effect of misslabelling on raw Logistic Regression"]},{"cell_type":"code","execution_count":null,"id":"6392f9e1","metadata":{"id":"6392f9e1","outputId":"640aefa1-68d1-499b-c3ef-700b3073436f"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["#we need 1 different for each\n","logr1 = LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000)\n","logr2 = LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000)\n","logr3 = LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000)\n","logr4 = LogisticRegression(multi_class = 'multinomial', solver='lbfgs', max_iter=1000)\n","\n","#trainning with all cases\n","logr_raw=logr1.fit(X_train,y_train)\n","logr_light=logr2.fit(X_train,light_mislabel)\n","logr_mid=logr3.fit(X_train,mid_mislabel)\n","logr_hard=logr4.fit(X_train,hard_mislabel)\n","\n","#predicting\n","predicted_raw = logr_raw.predict(X_test)\n","predicted_light = logr_light.predict(X_test)\n","predicted_mid = logr_mid.predict(X_test)\n","predicted_hard = logr_hard.predict(X_test)"]},{"cell_type":"markdown","id":"fd9fa575","metadata":{"id":"fd9fa575"},"source":["No misslabel"]},{"cell_type":"code","execution_count":null,"id":"c3c04590","metadata":{"id":"c3c04590","outputId":"46314c71-854f-4394-f4f5-f476471def02"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       1.00      1.00      1.00       233\n","         GBM       1.00      1.00      1.00        38\n","          KI       0.99      1.00      1.00       124\n","          LU       1.00      0.97      0.99       119\n","          OV       1.00      1.00      1.00        49\n","           U       0.94      1.00      0.97        15\n","\n","    accuracy                           0.99       578\n","   macro avg       0.99      1.00      0.99       578\n","weighted avg       0.99      0.99      0.99       578\n","\n"]}],"source":["print(classification_report(y_test, predicted_raw))"]},{"cell_type":"markdown","id":"01e8df56","metadata":{"id":"01e8df56"},"source":["Light misslabel"]},{"cell_type":"code","execution_count":null,"id":"f37925ce","metadata":{"id":"f37925ce","outputId":"903dd02a-45f0-4f1d-e46f-02e9a3198872"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.99      0.96      0.97       233\n","         GBM       0.93      1.00      0.96        38\n","          KI       0.95      0.98      0.96       124\n","          LU       0.97      0.93      0.95       119\n","          OV       0.92      0.98      0.95        49\n","           U       0.87      0.87      0.87        15\n","\n","    accuracy                           0.96       578\n","   macro avg       0.94      0.95      0.95       578\n","weighted avg       0.96      0.96      0.96       578\n","\n"]}],"source":["print(classification_report(y_test, predicted_light))"]},{"cell_type":"markdown","id":"24d1f364","metadata":{"id":"24d1f364"},"source":["Mid misslabel"]},{"cell_type":"code","execution_count":null,"id":"baa71711","metadata":{"id":"baa71711","outputId":"7c0885b3-e482-4d64-c121-81bf488e1e36"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.94      0.85      0.89       233\n","         GBM       0.72      0.87      0.79        38\n","          KI       0.85      0.86      0.86       124\n","          LU       0.82      0.78      0.80       119\n","          OV       0.71      0.80      0.75        49\n","           U       0.40      0.67      0.50        15\n","\n","    accuracy                           0.83       578\n","   macro avg       0.74      0.80      0.76       578\n","weighted avg       0.85      0.83      0.84       578\n","\n"]}],"source":["print(classification_report(y_test, predicted_mid))"]},{"cell_type":"markdown","id":"61d139b7","metadata":{"id":"61d139b7"},"source":["Hard misslabel"]},{"cell_type":"code","execution_count":null,"id":"7eb597bf","metadata":{"id":"7eb597bf","outputId":"99a04a0c-304d-4b8b-d034-71f3bf56c166"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","          BC       0.55      0.27      0.37       233\n","         GBM       0.17      0.39      0.24        38\n","          KI       0.30      0.25      0.27       124\n","          LU       0.28      0.24      0.25       119\n","          OV       0.12      0.24      0.16        49\n","           U       0.03      0.13      0.05        15\n","\n","    accuracy                           0.26       578\n","   macro avg       0.24      0.26      0.22       578\n","weighted avg       0.36      0.26      0.29       578\n","\n"]}],"source":["print(classification_report(y_test, predicted_hard))"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}
